{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/conda/envs/all/lib/python3.7/site-packages/ipykernel_launcher.py:82: UserWarning: Cannot find pickled properties count at\n",
      "resources/properties_count.pickle.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    This file generates subgraphs and SPARQL for a given set of entites.\n",
    "\n",
    "    Changelog:\n",
    "        -> Removed probabilistic filtering (for easier deployment)\n",
    "\n",
    "        @TODO: Figure out why _fill_one_template_ fucks up answer and answer type, num\n",
    "\"\"\"\n",
    "\n",
    "# Importing some external libraries\n",
    "from pprint import pprint\n",
    "from oset import oset\n",
    "import textwrap\n",
    "import warnings\n",
    "import pickle\n",
    "import random\n",
    "import json\n",
    "import copy\n",
    "import uuid\n",
    "\n",
    "# Importing internal classes/libraries\n",
    "from utils.goodies import *\n",
    "import utils.dbpedia_interface as db_interface\n",
    "import utils.natural_language_utilities as nlutils\n",
    "from utils import subgraph\n",
    "\n",
    "formatwarning_orig = warnings.formatwarning\n",
    "warnings.formatwarning = lambda message, category, filename, lineno, line=None: \\\n",
    "    formatwarning_orig(textwrap.fill(str(message)), category, filename, lineno, line=\"\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# LOCATION\n",
    "DONE_SPARQLS_LOC = \"sparqls/template%d.txt\"\n",
    "DONE_ENTITIES_DONE_LOC = './sparqls/entities.txt'\n",
    "RES_RELATION_LOC = 'resources/relations.txt'\n",
    "RES_ENTITIY_CLASSES_LOC = 'resources/entity_classes.txt'\n",
    "RES_ENTITIES_LOC = 'resources/entities.txt'\n",
    "RES_TEMPLATES_LOC = 'templates.json'\n",
    "RES_PREDICATE_COUNT_LOC = 'resources/properties_count.pickle'\n",
    "\n",
    "# Contains the whitelisted props types\n",
    "predicates = open(RES_RELATION_LOC, 'r').read().split('\\n')\n",
    "\n",
    "# Contains whitelisted entities classes\n",
    "entity_classes = open(RES_ENTITIY_CLASSES_LOC, 'r').read().split('\\n')\n",
    "\n",
    "# Contains list of entities for which the question would be asked\n",
    "entities = oset(open(RES_ENTITIES_LOC, 'r').read().split('\\n'))\n",
    "entities_done = oset(open(DONE_ENTITIES_DONE_LOC, 'r+').read().split('\\n'))\n",
    "entities = list(entities - entities_done)\n",
    "\n",
    "# Contains all the SPARQL templates existing in templates.py\n",
    "templates = json.load(open(RES_TEMPLATES_LOC))\n",
    "\n",
    "# Some global vars to be filled in later.\n",
    "entity_went_bad = []\n",
    "sparqls = {}\n",
    "dbp = None\n",
    "\n",
    "# Some macros because hardcoding params kills puppies\n",
    "DEBUG = True\n",
    "NUM_ANSWER_COUNTABLE = 7\n",
    "NUM_ANSWER_MAX = 10\n",
    "FLUSH_THRESHOLD = 100\n",
    "FILTER_PRED, FILTER_LITERAL, FILTER_ENT = True, True, False\n",
    "DBP_NMSP = 'http://dbpedia.org/'  # DBpedia namespace\n",
    "SUBG_MAX_RESULTS = 50\n",
    "\n",
    "'''\n",
    "    A dictionary of properties. \n",
    "    **key** parent entity \n",
    "    **value** a dictionary {'predicate':count}\n",
    "        **key** of property and **value** being number of times it has already occurred .\n",
    "    {\"/agent\" : [ {\"/birthPlace\" : 1 }, {\"/deathPlace\" : 2}] }\n",
    "\n",
    "    This needs to be pickled. @TODO: When?\n",
    "'''\n",
    "try:\n",
    "    predicates_count = pickle.load(open(RES_PREDICATE_COUNT_LOC, 'rb'))\n",
    "except FileNotFoundError:\n",
    "    warnings.warn(\"Cannot find pickled properties count at %s.\" % RES_PREDICATE_COUNT_LOC)\n",
    "    # traceback.print_exc()\n",
    "    predicates_count = {}\n",
    "\n",
    "\n",
    "'''\n",
    "    Some SPARQL Queries.\n",
    "    Since this part of the code requires sending numerous convoluted queries to DB\n",
    "pedia,\n",
    "        we best not clutter the DBpedia interface class and rather simply declare them here.\n",
    "\n",
    "    Note: The names here can be confusing. Refer to the diagram (resources/nomenclature.png) \n",
    "        to know what each SPARQL query tries to do.\n",
    "'''\n",
    "one_triple_right = '''\n",
    "            SELECT DISTINCT ?p ?e\n",
    "            WHERE {\n",
    "                <%(e)s> ?p ?e .\n",
    "            }'''\n",
    "\n",
    "one_triple_left = '''\n",
    "            SELECT DISTINCT ?e ?p\n",
    "            WHERE {\n",
    "                ?e ?p <%(e)s> .\n",
    "            }'''\n",
    "\n",
    "\n",
    "def filter_triples(_results,\n",
    "                   _keep_no_results=None,\n",
    "                   _filter_dbpedia=False,\n",
    "                   _filter_predicates=True,\n",
    "                   _filter_literals=True,\n",
    "                   _filter_entities=False,\n",
    "                   _filter_count=False,\n",
    "                   _k=5\n",
    "                   ):\n",
    "    \"\"\"\n",
    "    Implements pruing in the results.\n",
    "    Used to push the results of different queries into the subgraph.\n",
    "\n",
    "    Logic:\n",
    "        It First prunes based on properties and entite classes.\n",
    "        After this if the result length is still more than _keep_no_result,\n",
    "            randomly selects _keep_no_results from the result list.\n",
    "        The output can then be sent to be put in the graph.\n",
    "\n",
    "    @TODO: implement _filter_entities filter\n",
    "\n",
    "    :param _results: list: a result list which contains the sparql variables '?e', '?p', '?type'.\n",
    "                They can be of either left or right queries as the defined above.\n",
    "    :param _keep_no_results: int: a hard limit to the length of list. Leave if want unbounded.\n",
    "    :param _filter_dbpedia: bool: if True, only things starting with http://dbpedia.org/... will be returned.\n",
    "    :param _filter_predicates: bool: if True, only properties existing in properties whitelist will be returned.\n",
    "    :param _filter_literals: bool: if True, no literals will be returned.\n",
    "    :param _filter_entities: bool: if True, only entities belonging to `entity_classes` will be returned.\n",
    "    :param _filter_count: bool: if True we ensure that only _k instances of a property alongwith entitytype are returned\n",
    "    :param _k: int: limit on _filter_count\n",
    "\n",
    "    :return: A list of results which can directly be used for inserting into a graph\n",
    "    \"\"\"\n",
    "    global predicates_count\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    for result in _results[u'results'][u'bindings']:\n",
    "        pred = result[u'p'][u'value']\n",
    "        ent = result[u'e'][u'value']\n",
    "\n",
    "        # Put in filters\n",
    "        if _filter_dbpedia and (not pred.startswith(DBP_NMSP) or not ent.startswith(DBP_NMSP)):\n",
    "            continue\n",
    "        if _filter_predicates and pred not in predicates:\n",
    "            continue\n",
    "        if _filter_literals and nlutils.is_literal(ent):\n",
    "            continue\n",
    "\n",
    "        cls = dbp.get_most_specific_class(ent) if not nlutils.is_literal(ent) else None\n",
    "\n",
    "        # Log this in property count\n",
    "        count = predicates_count.setdefault(cls, {}).setdefault(pred, 0)\n",
    "        if _filter_count and count > _k:\n",
    "            continue\n",
    "        else:\n",
    "            predicates_count[cls][pred] += 1\n",
    "\n",
    "        results_list.append(result)\n",
    "\n",
    "    if _keep_no_results and (len(results_list) > _keep_no_results):\n",
    "        return random.sample(results_list, _keep_no_results)\n",
    "\n",
    "    return results_list\n",
    "\n",
    "\n",
    "def insert_triples_in_subgraph(subg, _results, _outgoing, _origin, _save_classes=False):\n",
    "    \"\"\"\n",
    "        Function used to push the results of different queries into the subgraph.\n",
    "        USAGE: only within the get_local_subgraph function.\n",
    "\n",
    "    :param subg: the subgraph object within which the triples are to be pushed\n",
    "    :param _results: a result list which contains the sparql variables 'e' and 'p'.\n",
    "                They can be of either left or right queries as the cell above.\n",
    "    :param _outgoing: True -> one triple right; False -> one triple left\n",
    "    :param _origin: the results variable only gives us one p and one e.\n",
    "                Depending on the direction, this node will act as the other e to complete the triple\n",
    "    :param _save_classes: boolL True -> also store the rdftype value of the entites\n",
    "    :return: Nothing\n",
    "    \"\"\"\n",
    "\n",
    "    for result in _results:\n",
    "        # Parse the results into local variables (for readibility)\n",
    "\n",
    "        # A bit of cleaning here might help\n",
    "\n",
    "        pred = result[u'p'][u'value']\n",
    "        enty = result[u'e'][u'value']\n",
    "        cls = dbp.get_most_specific_class(enty) if _save_classes else ''\n",
    "\n",
    "        if not nlutils.is_clean_url(enty):\n",
    "            continue\n",
    "\n",
    "        if not nlutils.is_clean_url(pred):\n",
    "            continue\n",
    "\n",
    "        # Push the data in subgraph\n",
    "        subg.insert([subgraph.PredEntTuple(pred, enty, cls)], _origin=_origin, _outgoing=_outgoing)\n",
    "\n",
    "\n",
    "def _generate_sparqls_(_uri, _dbp):\n",
    "    \"\"\"\n",
    "        Internal fn which orchestrates everything. Calls fn to gen subgraph,\n",
    "            and then generates SPARQL based on the subgraph\n",
    "\n",
    "    :param _uri: str of entity\n",
    "    :param _dbp: dbpedia interface obj\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(f\"{_uri}: Started.\")\n",
    "    with Timer() as timed:\n",
    "        # Generate the local subgraph\n",
    "        graph = generate_subgraph(_uri, _dbp=_dbp)\n",
    "    print(\"%(ent)s: Done generating subgraph. Time: %(time).03f.\" % {'ent': _uri, 'time': timed.interval})\n",
    "\n",
    "    with Timer() as timed:\n",
    "        # Generate the local subgraph\n",
    "        fill_templates(graph, _dbp=_dbp)\n",
    "    print(\"%(ent)s: Done generating sparqls. Time: %(time).03f.\" % {'ent': _uri, 'time': timed.interval})\n",
    "    print(\"%(ent)s: Time spent inside subG: %(time).03f.\" % {'ent': _uri, 'time': graph.time_maps})\n",
    "\n",
    "\n",
    "def _fill_one_template_(_template, _map, _graph, _dbp):\n",
    "    \"\"\"\n",
    "        Function to fill a given template.\n",
    "            by juxtaposing the mapping on the template.\n",
    "\n",
    "        Moreover, it also has certain functionalities that help the down the line.\n",
    "             -> Returns the answer of the query, and the answer type\n",
    "             -> In some templates, it also fetches the intermediate hidden variable and it's types too.\n",
    "\n",
    "        Reject:\n",
    "            -> if count template and less answers, reject.\n",
    "            -> if not rdf constraints based template, and some answers have no common class with _graph.uri, reject.\n",
    "\n",
    "        -> create copy of template from the list\n",
    "        -> get the needed metadata\n",
    "        -> push it in the list\n",
    "        :param _template: dict: one of the template from `templates.json`\n",
    "        :param _map: dict: of vars needed in template. (maybe more)\n",
    "        :param _graph: Subgraph obj\n",
    "        :param _dbp: dbpedia obj\n",
    "\n",
    "        :return _template: dict.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a copy of the template\n",
    "    template = copy.copy(_template)\n",
    "\n",
    "    # From the template, make a rigid query using mappings\n",
    "    try:\n",
    "        template['query'] = template['template'] % _map\n",
    "        template['_id'] = uuid.uuid4().hex\n",
    "        template['corrected'] = 'false'\n",
    "        template['entity'] = _graph.uri\n",
    "    except KeyError:\n",
    "        raise InvalidTemplateMappingError(\"Something doesn't fit right. Var Map %s\" % str(_map))\n",
    "\n",
    "    # Include the mapping within the template object\n",
    "    template['mapping'] = _map\n",
    "\n",
    "    # @TODO: try finding it in the subgraph, and getting the class from there.\n",
    "    # Also get the classes of all the things we're putting in our SPARQL\n",
    "    template['mapping_type'] = {key: dbp.get_most_specific_class(value)\n",
    "                                for key, value in _map.items()}\n",
    "\n",
    "    # Get the Answer of the query\n",
    "    answer = dbp.get_answer(template['query'])\n",
    "    classes_uri = set(dbp.get_type_of_resource(template['entity'], _filter_dbpedia=True))\n",
    "    template['answer_type'] = list(classes_uri)\n",
    "\n",
    "    # Check for reject condition 1\n",
    "    if template[\"type\"] == \"count\":\n",
    "        if (int(answer[list(answer.keys())[0]][0])) < NUM_ANSWER_COUNTABLE:\n",
    "            return None\n",
    "\n",
    "    if 'uri' in answer.keys():\n",
    "        classes_answer = [dbp.get_type_of_resource(uri, _filter_dbpedia=True) for uri in answer['uri']\n",
    "                          if not nlutils.is_literal(uri)]\n",
    "\n",
    "        # Check for reject condition 2\n",
    "        if 300 >= template['template_id']:\n",
    "            # If not a template with rdf type constraint\n",
    "            for cls in classes_answer:\n",
    "                if not classes_uri & set(cls):\n",
    "                    # No common class\n",
    "                    return None\n",
    "\n",
    "    # Store answers accordingly\n",
    "    if template['type'] == 'ask':\n",
    "        template['answer_num'] = -1\n",
    "    else:\n",
    "        # Clamp the answers at NUM_ANSWERS_MAX and put in template IF NOT BOOLEAN\n",
    "        answer = {k: v[:max(len(list(set(v))), NUM_ANSWER_MAX)] for k, v in answer.items()}\n",
    "        if template['type'] == 'count':\n",
    "            template['answer_num'] = -1\n",
    "        else:\n",
    "            template['answer_num'] = len(list(set(answer['uri'])))\n",
    "\n",
    "    template['answer'] = answer\n",
    "\n",
    "    return template\n",
    "\n",
    "\n",
    "def get_vars(_template):\n",
    "    _vars = _template.get('vars', nlutils.get_variables(_template['template']))\n",
    "    _vars += ['class_uri'] if 'class_uri' not in _vars else []\n",
    "    return _vars\n",
    "\n",
    "\n",
    "def add(_data):\n",
    "    \"\"\"\n",
    "        Safely store generated template obj (full with SPARQL and whatnot) in a global var.\n",
    "\n",
    "    :param _data: dict\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    global sparqls\n",
    "    if _data:\n",
    "        sparqls[_data['template_id']] = sparqls.get(_data['template_id'], []) + [_data]\n",
    "    return True\n",
    "\n",
    "\n",
    "def flush(_uri):\n",
    "    \"\"\"\n",
    "        @TODO: Need a lock here\n",
    "\n",
    "        :param _uri: str of the entity in question\n",
    "        :return: Nothing\n",
    "    \"\"\"\n",
    "    global sparqls\n",
    "\n",
    "    print(f\"\\tFlushing sparqls for {_uri}\")\n",
    "    for t_id, data in sparqls.items():\n",
    "\n",
    "        with open(DONE_SPARQLS_LOC % t_id, \"a+\") as fo:\n",
    "            for value in data:\n",
    "                fo.writelines(json.dumps(value) + \"\\n\")\n",
    "\n",
    "    sparqls = {}\n",
    "\n",
    "    # Also put the entity in the list\n",
    "    with open(DONE_ENTITIES_DONE_LOC, \"a+\") as fo:\n",
    "        fo.writelines(_uri+'\\n')\n",
    "\n",
    "\n",
    "def fill_templates(_graph, _dbp):\n",
    "    \"\"\"\n",
    "        Will generate valid SPARQLs for different templates, based on the keys that the SPARQL needs.\n",
    "        Expects a populated Subgraph object.\n",
    "\n",
    "        :param _graph: Subgraph obj\n",
    "        :param _dbp: dbpedia interface obj\n",
    "        :return List of strings (SPARQL)\n",
    "    \"\"\"\n",
    "    for template in templates:\n",
    "        mappings = _graph.gen_maps(get_vars(template), template.get('equal', []))[:template.get('max', None)]\n",
    "\n",
    "        for mapping in mappings:\n",
    "            add(_data=_fill_one_template_(_template=template, _map=mapping, _graph=_graph, _dbp=_dbp))\n",
    "\n",
    "    # Write everything to disk\n",
    "    flush(_graph.uri)\n",
    "\n",
    "\n",
    "def generate_subgraph(_uri, _dbp):\n",
    "    \"\"\"\n",
    "        Returns a subgraph object.\n",
    "\n",
    "    :param _uri: str of entity\n",
    "    :param _dbp: dbpedia object\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new graph\n",
    "    g = subgraph.Subgraph(_uri, _type=_dbp.get_most_specific_class(_uri))\n",
    "\n",
    "    # ########## e ?p ?e (e_to_e_out and e_out) ##########\n",
    "    with Timer() as timer:\n",
    "\n",
    "        results = _dbp.shoot_custom_query(one_triple_right % {'e': _uri})\n",
    "        results = filter_triples(_results=results,\n",
    "                                 _keep_no_results=SUBG_MAX_RESULTS,\n",
    "                                 _filter_dbpedia=True,\n",
    "                                 _filter_predicates=FILTER_PRED,\n",
    "                                 _filter_literals=FILTER_LITERAL,\n",
    "                                 _filter_entities=FILTER_ENT,\n",
    "                                 _filter_count=False)\n",
    "        insert_triples_in_subgraph(g, _results=results, _outgoing=True, _origin=_uri, _save_classes=True)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"GenSub: 1-hop right for %(uri)s. Time: %(time).03f. Len: %(len)d\" %\n",
    "              {'uri': _uri, 'time': timer.interval, 'len': len(results)})\n",
    "\n",
    "    # ########## ?e ?p e (e_in and e_in_to_e) ##########\n",
    "    with Timer() as timer:\n",
    "\n",
    "        results = _dbp.shoot_custom_query(one_triple_left % {'e': _uri})\n",
    "        results = filter_triples(_results=results,\n",
    "                                 _keep_no_results=SUBG_MAX_RESULTS,\n",
    "                                 _filter_dbpedia=True,\n",
    "                                 _filter_predicates=FILTER_PRED,\n",
    "                                 _filter_literals=FILTER_LITERAL,\n",
    "                                 _filter_entities=FILTER_ENT,\n",
    "                                 _filter_count=False)\n",
    "        insert_triples_in_subgraph(g, _results=results, _outgoing=False, _origin=_uri, _save_classes=True)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"GenSub: 1-hop left for %(uri)s. Time: %(time).03f. Len: %(len)d\" %\n",
    "              {'uri': _uri, 'time': timer.interval, 'len': len(results)})\n",
    "\n",
    "    # ########## e p eout . eout ?p ?e (e_out_to_e_out_out and e_out_out) ##########\n",
    "    with Timer() as timer:\n",
    "\n",
    "        # Get all the e_out nodes back from the subgraph.\n",
    "        e_outs = g.right.entities\n",
    "        len_res = 0\n",
    "        for e_out in e_outs:\n",
    "            results = _dbp.shoot_custom_query(one_triple_right % {'e': e_out})\n",
    "            results = filter_triples(_results=results,\n",
    "                                     _keep_no_results=SUBG_MAX_RESULTS,\n",
    "                                     _filter_dbpedia=True,\n",
    "                                     _filter_predicates=FILTER_PRED,\n",
    "                                     _filter_literals=FILTER_LITERAL,\n",
    "                                     _filter_entities=FILTER_ENT,\n",
    "                                     _filter_count=False)\n",
    "            len_res = len(results)\n",
    "            insert_triples_in_subgraph(g, _results=results, _outgoing=True, _origin=e_out, _save_classes=True)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"GenSub: 2-hop right (e_out_to_e_out_out and e_out_out) for %(uri)s. Time: %(time).03f. Len: %(len)d\" %\n",
    "              {'uri': _uri, 'time': timer.interval, 'len': len_res})\n",
    "\n",
    "    # ########## e p eout . ?e ?p eout  (e_out_in and e_out_in_to_e_out) ##########\n",
    "    with Timer() as timer:\n",
    "\n",
    "        e_outs = g.right.entities\n",
    "        len_res = 0\n",
    "        for e_out in e_outs:\n",
    "            results = _dbp.shoot_custom_query(one_triple_left % {'e': e_out})\n",
    "            results = filter_triples(_results=results,\n",
    "                                     _keep_no_results=SUBG_MAX_RESULTS,\n",
    "                                     _filter_dbpedia=True,\n",
    "                                     _filter_predicates=FILTER_PRED,\n",
    "                                     _filter_literals=FILTER_LITERAL,\n",
    "                                     _filter_entities=FILTER_ENT,\n",
    "                                     _filter_count=False)\n",
    "            len_res += len(results)\n",
    "            # print(\"Here \",len(results), e_out)\n",
    "            insert_triples_in_subgraph(g, _results=results, _outgoing=False, _origin=e_out, _save_classes=True)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"GenSub: 2-hop left (e_out_in and e_out_in_to_e_out) for %(uri)s. Time: %(time).03f. Len: %(len)d\" %\n",
    "              {'uri': _uri, 'time': timer.interval, 'len': len_res})\n",
    "\n",
    "    # ########## ?e ?p ein . ein p e  (e_in_in and e_in_in_to_e_in) ##########\n",
    "    with Timer() as timer:\n",
    "\n",
    "        e_ins = g.left.entities\n",
    "        len_res = 0\n",
    "        for e_in in e_ins:\n",
    "            results = _dbp.shoot_custom_query(one_triple_left % {'e': e_in})\n",
    "            results = filter_triples(_results=results,\n",
    "                                     _keep_no_results=SUBG_MAX_RESULTS,\n",
    "                                     _filter_dbpedia=True,\n",
    "                                     _filter_predicates=FILTER_PRED,\n",
    "                                     _filter_literals=FILTER_LITERAL,\n",
    "                                     _filter_entities=FILTER_ENT,\n",
    "                                     _filter_count=False)\n",
    "            len_res += len(results)\n",
    "            insert_triples_in_subgraph(g, _results=results, _outgoing=False, _origin=e_in, _save_classes=True)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"GenSub: 2-hop left (e_in_in and e_in_in_to_e_in) for %(uri)s. Time: %(time).03f. Len: %(len)d\" %\n",
    "              {'uri': _uri, 'time': timer.interval, 'len': len_res})\n",
    "\n",
    "    # ########## ein ?p ?e . ein p e  (e_in_to_e_in_out and e_in_out) ##########\n",
    "    with Timer() as timer:\n",
    "\n",
    "        e_ins = g.left.entities\n",
    "        len_res = 0\n",
    "        for e_in in e_ins:\n",
    "            results = _dbp.shoot_custom_query(one_triple_right % {'e': e_in})\n",
    "            results = filter_triples(_results=results,\n",
    "                                     _keep_no_results=SUBG_MAX_RESULTS,\n",
    "                                     _filter_dbpedia=True,\n",
    "                                     _filter_predicates=FILTER_PRED,\n",
    "                                     _filter_literals=FILTER_LITERAL,\n",
    "                                     _filter_entities=FILTER_ENT,\n",
    "                                     _filter_count=False)\n",
    "            len_res = len(results)\n",
    "            insert_triples_in_subgraph(g, _results=results, _outgoing=True, _origin=e_in, _save_classes=True)\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"GenSub: 2-hop right (e_in_to_e_in_out and e_in_out) for %(uri)s. Time: %(time).03f. Len: %(len)d\" %\n",
    "              {'uri': _uri, 'time': timer.interval, 'len': len_res})\n",
    "\n",
    "    # Pushed all the six kind of nodes in the subgraph. Done!\n",
    "    return g\n",
    "\n",
    "\n",
    "def generate_sparqls(_dbp):\n",
    "    \"\"\"\n",
    "        The main function which generates and writes sparqls to file.\n",
    "\n",
    "    :param _dbp: Dbpedia Interface obj.\n",
    "    :return: @TODO: what indeed\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Num ents: %d\" % len(entities))\n",
    "\n",
    "    for ent in entities:\n",
    "        _generate_sparqls_(ent, _dbp)\n",
    "\n",
    "    # Commented it out to help the case of cluttered output folder\n",
    "    # for key in sparqls:\n",
    "    #     with open('output/template%d.txt' % key, 'a+') as out:\n",
    "    #         pprint(sparqls[key], stream=out)\n",
    "\n",
    "    print(\"Pickling properties count to file\")\n",
    "    pickle.dump(predicates_count, open('resources/properties_count.pickle', 'w+'))\n",
    "\n",
    "    print(\"Trying to write SPARQLs to file!\")\n",
    "    for key in sparqls:\n",
    "        fo = open('sparqls/template%d.txt' % key, 'a+')\n",
    "        for value in sparqls[key]:\n",
    "            fo.writelines(json.dumps(value) + \"\\n\")\n",
    "        fo.close()\n",
    "\n",
    "    print(\"These entities did not generating something\")\n",
    "    pprint(list(set(entity_went_bad)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/Unification_of_Nepal. Returning owl:Thing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenSub: 1-hop right for http://dbpedia.org/resource/Nepal. Time: 1.729. Len: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Cyclone_Hudhud.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/1995_India_cyclone. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/2010_Okhaldhunga_Twin_Otter_crash.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/LGBT_rights_in_Nepal. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/2011_Nepal_census. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/2014_Doti_bus_accident. Returning\n",
      "owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/2014_Jajarkot_bus_accident. Returning\n",
      "owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/Pasang_Lhamu_bus_crash. Returning\n",
      "owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/Western_Himalayan_broadleaf_forests.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/Dhaneshwor_Temple. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/Young_Communist_League,_Nepal. Returning\n",
      "owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/Cricket_Association_of_Nepal. Returning\n",
      "owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/BackoffIndia.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Namaste_Falls.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Hong_Kong_natio\n",
      "nal_football_team_results_(1980–89). Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Sambha_gompa.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Koirala_family.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Bhutan_national\n",
      "_under-19_football_team_results. Returning owl:Thing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenSub: 1-hop left for http://dbpedia.org/resource/Nepal. Time: 242.358. Len: 50\n",
      "GenSub: 2-hop right (e_out_to_e_out_out and e_out_out) for http://dbpedia.org/resource/Nepal. Time: 5.145. Len: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/2015_Nepal_Premier_League. Returning\n",
      "owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/18th_SAARC_summit. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/2011_North_Kore\n",
      "a_national_football_team_results. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Bhutan_national\n",
      "_under-17_football_team_results. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/2012_Palestine_\n",
      "national_football_team_results. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/Tibetan_alphabet. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Limbu_alphabet.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Kamariya.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/Devanagari_Braille. Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for\n",
      "http://dbpedia.org/resource/Nepal–Britain_Treaty_of_1923. Returning\n",
      "owl:Thing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenSub: 2-hop left (e_out_in and e_out_in_to_e_out) for http://dbpedia.org/resource/Nepal. Time: 25.878. Len: 826\n",
      "GenSub: 2-hop left (e_in_in and e_in_in_to_e_in) for http://dbpedia.org/resource/Nepal. Time: 4.588. Len: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Jivan_Luitel.\n",
      "Returning owl:Thing.\n",
      "/home/priyansh/Dev/sda/lcquad/dev/utils/dbpedia_interface.py:463: EntityTypeNotFound: Could not find classes for http://dbpedia.org/resource/Asian.\n",
      "Returning owl:Thing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenSub: 2-hop right (e_in_to_e_in_out and e_in_out) for http://dbpedia.org/resource/Nepal. Time: 9.307. Len: 7\n"
     ]
    }
   ],
   "source": [
    "dbp = db_interface.DBPedia(_verbose=True, _caching=True)\n",
    "ent = 'http://dbpedia.org/resource/Nepal'\n",
    "graph = generate_subgraph(ent, _dbp=dbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumppath = './utils/nepal.pkl'\n",
    "pickle.dump(graph, open(dumppath,'wb+'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
