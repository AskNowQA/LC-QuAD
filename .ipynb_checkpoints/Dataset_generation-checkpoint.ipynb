{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description\n",
    "@todo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nomenclature\n",
    "Property names are derived out of entities they join.\n",
    "\n",
    "The ground/root entity is called ent0\n",
    "Add the word out/in when required as shown in photo here: \n",
    "<img src=\"files/resources/nomenclature.png\">\n",
    "@todo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Importing some external libraries\n",
    "from pprint import pprint\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import json\n",
    "import copy\n",
    "\n",
    "#Importing internal classes/libraries\n",
    "import utils.dbpedia_interface as db_interface\n",
    "import utils.natural_language_utilities as nlutils\n",
    "import utils.subgraph as subgraph\n",
    "\n",
    "#@TODO: put this class there\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Initializing some stuff. Namely: DBpedia interface class.\n",
    "    Reading the list of 'relevant' properties.\n",
    "'''\n",
    "\n",
    "dbp = None\t#DBpedia interface object #To be instantiated when the code is run by main script/unit testing script\n",
    "relevant_properties = open('resources/relation_whitelist.txt').read().split('\\n')    #Contains the whitelisted props types\n",
    "templates = json.load(open('templates.py'))   #Contains all the templates existing in templates.py\n",
    "sparqls = {}   #Dict of the generated SPARQL Queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Some SPARQL Queries.\n",
    "    Since this part of the code requires sending numerous convoluted queries to DBpedia, \n",
    "        we best not clutter the DBpedia interface class and rather simply declare them here.\n",
    "        \n",
    "    Note: The names here can be confusing. Refer to the diagram above to know what each SPARQL query tries to do.\n",
    "'''\n",
    "\n",
    "one_triple_right = '''\n",
    "            SELECT DISTINCT ?p ?e \n",
    "            WHERE { \n",
    "                <%(e)s> ?p ?e \n",
    "            }'''\n",
    "\n",
    "one_triple_left = '''\n",
    "            SELECT DISTINCT ?e ?p\n",
    "            WHERE {\n",
    "                ?e ?p <%(e)s>\n",
    "            }'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    This cell houses the script which will build a subgraph as shown in picture above for each a given URI.\n",
    "    @TODO: do something in cases where certain nodes of the local subgraph are not found. \n",
    "            Will the code throw errors? How to you take care of them?\n",
    "'''\n",
    "\n",
    "def insert_triple_in_subgraph(G, _results, _labels, _direction, _origin_node, _filter_properties = True, _filter_literals = True):\n",
    "    '''\n",
    "        Function used to push the results of different queries into the subgraph.\n",
    "        USAGE: only within the get_local_subgraph function.\n",
    "        \n",
    "        INPUTS:\n",
    "        _subgraph: the subgraph object within which the triples are to be pushed\n",
    "        _results: a result list which contains the sparql variables 'e' and 'p'. \n",
    "                They can be of either left or right queries as the cell above\n",
    "        _labels: a tuple with three strings, which depict the nomenclature of the resources to be pushed\n",
    "        _direction: True -> one triple right; False -> one triple left\n",
    "        _origin_node: the results variable only gives us one p and one e. \n",
    "                Depending on the direction, this node will act as the other e to complete the triple  \n",
    "        _filter_properties: if True, only properties existing in properties whitelist will be pushed in.\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    for result in _results[u'results'][u'bindings']:\n",
    "        #Parse the results into local variables (for readibility)\n",
    "        prop = result[u'p'][u'value']\n",
    "        ent = result[u'e'][u'value']\n",
    "        \n",
    "        if _filter_literals:\n",
    "        \tif nlutils.has_literal(ent):\n",
    "        \t\tcontinue\n",
    "\n",
    "        if _filter_properties:\n",
    "            \n",
    "            #Filter results based on important properties\n",
    "            if not prop.split('/')[-1] in relevant_properties:\n",
    "                continue\n",
    "        \n",
    "        #Finally, insert, based on direction\n",
    "        if _direction == True:\n",
    "            #Right\n",
    "            subgraph.insert(G=G, data=[ (_labels[0],_origin_node), (_labels[1],prop), (_labels[2],ent) ])\n",
    "            \n",
    "        elif _direction == False:\n",
    "            #Left\n",
    "            subgraph.insert(G=G, data=[(_labels[0],ent), (_labels[1],prop), (_labels[2],_origin_node) ])       \n",
    "\n",
    "            \n",
    "            \n",
    "def get_local_subgraph(_uri):\n",
    "    #Collecting required variables: DBpedia interface, and a new subgraph\n",
    "    global dbp\n",
    "    \n",
    "    #Create a new graph\n",
    "    G = nx.DiGraph()\n",
    "    access = subgraph.accessGraph(G)\n",
    "    \n",
    "    \n",
    "    ########### e ?p ?e (e_to_e_out and e_out) ###########\n",
    "    \n",
    "    results = dbp.shoot_custom_query(one_triple_right % {'e': _uri})\n",
    "    labels = ('e','e_to_e_out','e_out')\n",
    "\n",
    "    #Insert results in subgraph\n",
    "    insert_triple_in_subgraph(G, _results=results, \n",
    "                             _labels=labels, _direction=True, \n",
    "                             _origin_node=_uri, _filter_properties=True)\n",
    "    \n",
    "    ########### ?e ?p e (e_in and e_in_to_e) ###########\n",
    "    \n",
    "    results = dbp.shoot_custom_query(one_triple_left % {'e':_uri} )\n",
    "    labels = ('e_in', 'e_in_to_e','e')\n",
    "    \n",
    "    #Insert results in subgraph\n",
    "    insert_triple_in_subgraph(G, _results=results, \n",
    "                             _labels=labels, _direction=False, \n",
    "                             _origin_node=_uri, _filter_properties=True)\n",
    "                        \n",
    "    ########### e p eout . eout ?p ?e (e_out_to_e_out_out and e_out_out) ###########\n",
    "    \n",
    "    #Get all the eout nodes back from the subgraph.\n",
    "    e_outs = []\n",
    "    op = access.return_outnodes('e')\n",
    "    for x in op: \n",
    "        for tup in x:\n",
    "            e_outs.append(tup[1].getUri())\n",
    "            \n",
    "    labels = ('e_out','e_out_to_e_out_out','e_out_out')\n",
    "    \n",
    "    for e_out in e_outs:\n",
    "        results = dbp.shoot_custom_query(one_triple_right % {'e' : e_out})\n",
    "        \n",
    "        #Insert results in subgraph\n",
    "        insert_triple_in_subgraph(G, _results=results, \n",
    "                                 _labels=labels, _direction=True, \n",
    "                                 _origin_node=e_out, _filter_properties=True)\n",
    "    \n",
    "    ########### e p eout . ?e ?p eout  (e_out_in and e_out_in_to_e_out) ###########\n",
    "    \n",
    "    #Use the old e_outs variable\n",
    "    labels = ('e_out_in','e_out_in_to_e_out','e_out')\n",
    "    \n",
    "    for e_out in e_outs:\n",
    "        results = dbp.shoot_custom_query(one_triple_left % {'e' : e_out})\n",
    "        \n",
    "        #Insert results in subgraph\n",
    "        insert_triple_in_subgraph(G, _results=results, \n",
    "                                 _labels=labels, _direction=False, \n",
    "                                 _origin_node=e_out, _filter_properties=True)\n",
    "        \n",
    "    ########### ?e ?p ein . ein p e  (e_in_in and e_in_in_to_e_in) ###########\n",
    "    \n",
    "    #Get all the ein nodes back from subgraph\n",
    "    e_ins = []\n",
    "    op = access.return_innodes('e')\n",
    "    for x in op:\n",
    "        for tup in x:\n",
    "            e_ins.append(tup[0].getUri())\n",
    "    \n",
    "    \n",
    "    labels = ('e_in_in','e_in_in_to_e_in','e_in')\n",
    "    \n",
    "    for e_in in e_ins:\n",
    "        results = dbp.shoot_custom_query(one_triple_left % {'e': e_in})\n",
    "        \n",
    "        #Insert results in subgraph\n",
    "        insert_triple_in_subgraph(G, _results=results, \n",
    "                                 _labels=labels, _direction=False, \n",
    "                                 _origin_node=e_in, _filter_properties=True)\n",
    "        \n",
    "    ########### ein ?p ?e . ein p e  (e_in_to_e_in_out and e_in_out) ###########\n",
    "    \n",
    "    #Use the old e_ins variable\n",
    "    labels = ('e_in','e_in_to_e_in_out','e_in_out')\n",
    "    \n",
    "    for e_in in e_ins:\n",
    "        results = dbp.shoot_custom_query(one_triple_right % {'e': e_in })\n",
    "        \n",
    "        #Insert results in subgraph\n",
    "        insert_triple_in_subgraph(G, _results=results, \n",
    "                                 _labels=labels, _direction=True, \n",
    "                                 _origin_node=e_in, _filter_properties=True)\n",
    "    \n",
    "    \n",
    "    #Pushed all the six kind of nodes in the subgraph. Done!\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_specific_template(_template_id, _mapping, _debug = False):\n",
    "    '''\n",
    "        Function to fill a specific template.\n",
    "        Given the template ID, it is expected to fetch the template from the set \n",
    "            and juxtapose the mapping on the template.\n",
    "            \n",
    "        Moreover, it also has certain functionalities that help the future generation of verbalizings.\n",
    "             -> Returns the answer of the query, and the answer type\n",
    "             -> In some templates, it also fetches the intermediate hidden variable and it's types too.\n",
    "    \n",
    "        -> create copy of template from the list\n",
    "        -> get the needed metadata\n",
    "        -> push it in the list\n",
    "    '''\n",
    "    \n",
    "    global sparql, templates, outputfile\n",
    "    \n",
    "    #Create a copy of the template\n",
    "    template = [x for x in templates if x['id'] == _template_id][0]\n",
    "    template = copy.copy(template)\n",
    "    \n",
    "    try:\n",
    "        template['query'] = template['template'] % _mapping\n",
    "    except KeyError:\n",
    "        print \"fill_specific_template: ERROR. Mapping does not match.\"\n",
    "        return False\n",
    "    \n",
    "    template['mapping'] = _mapping\n",
    "    \n",
    "    #Get the Answer of the query\n",
    "#     template['answer'] = dbp.get_answer()\n",
    "    \n",
    "    \n",
    "    if _debug:\n",
    "        pprint(template)\n",
    "    \n",
    "    #Push it onto the SPARQL List\n",
    "    try:\n",
    "        sparqls[_template_id].append(template)\n",
    "    except:\n",
    "        sparqls[_template_id] = [ template ]\n",
    "\n",
    "    #@TODO: Periodic writes to disk\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fill_templates(_graph,_uri):\n",
    "    '''\n",
    "        This function is programmed to traverse through the Subgraph and create mappings for templates\n",
    "\n",
    "        Per template traverse the graph, and pick out the needed stuff in local variables\n",
    "    '''\n",
    "    \n",
    "    global dbp\n",
    "    \n",
    "    access = subgraph.accessGraph(_graph)\n",
    "    \n",
    "    ''' \n",
    "        Template #1: \n",
    "            SELECT DISTINCT ?uri WHERE {?uri <%(e_to_e_out)s> <%(e_out)s> } \n",
    "        Find e_out and e_to_e_out.\n",
    "    '''\n",
    "    \n",
    "    #Query the graph for outnodes from e\n",
    "    op = access.return_outnodes('e')\n",
    "    \n",
    "    for triple in op[0]:\n",
    "        \n",
    "        #Making the variables explicit (for the sake of readability)\n",
    "        e_out = triple[1].getUri()\n",
    "        e_to_e_out = triple[2]['object'].getUri()\n",
    "    \n",
    "        #Create a mapping (in keeping with the templates' placeholder names)\n",
    "        mapping = {'e_out': e_out, 'e_to_e_out': e_to_e_out }\n",
    "        \n",
    "        #Throw it to a function who will put it in the list with appropriate bookkeeping\n",
    "        fill_specific_template(_template_id=1, _mapping=mapping)\n",
    "        \n",
    "    \n",
    "    ''' \n",
    "        Template #2: \n",
    "            SELECT DISTINCT ?uri WHERE { <%(e_in)s> <%(e_in_to_e)s> ?uri }\n",
    "        Find e_in and e_in_to_e.\n",
    "    '''\n",
    "    \n",
    "    #Query the graph for innodes to e\n",
    "    op = access.return_innodes('e')\n",
    "    \n",
    "    for triple in op[0]:\n",
    "    \n",
    "        #Making the variables explicit (for the sake of readability)\n",
    "        e_in = triple[0].getUri()\n",
    "        e_in_to_e = triple[2]['object'].getUri()\n",
    "        \n",
    "        #Create a mapping (in keeping with the templates' placeholder names)\n",
    "        mapping = {'e_in':e_in, 'e_in_to_e': e_in_to_e}\n",
    "        \n",
    "        #Throw it to a function who will put it in the list with appropriate bookkeeping\n",
    "        fill_specific_template( _template_id=2, _mapping=mapping)\n",
    "        \n",
    "        \n",
    "    ''' \n",
    "        Template #3: \n",
    "            SELECT DISTINCT ?uri WHERE { <%(e_in_in)s> <%(e_in_in_to_e_in)s> ?x . ?x <%(e_in_to_e)s> ?uri }\n",
    "        Find e_in and e_in_to_e.\n",
    "    '''\n",
    "    \n",
    "    #Query the graph for innode to e and relevant properties\n",
    "    op = access.return_innodes('e')\n",
    "    \n",
    "    #Create a list of all these (e_in, e_in_to_e)\n",
    "    one_triple_left_map = { triple[0].getUri(): triple[2]['object'].getUri()  for triple in op[0] }\n",
    "    pprint(one_triple_left)\n",
    "        \n",
    "    #Collect all e_in_in and e_in_in_to_e_in \n",
    "    op = access.return_innodes('e_in')\n",
    "        \n",
    "    #This 'op' has the e_in_in and the prop for all e_in's. We now need to map one to the other.\n",
    "    for list_of_triples in op:\n",
    "\n",
    "        #Some triple are simply empty. Ignore them.\n",
    "        if len(list_of_triples) == 0:\n",
    "            continue\n",
    "\n",
    "        ### Mapping e_in_in's to relevant e_in's ###\n",
    "        \n",
    "        #Pick one triple from the list.\n",
    "        e_in = list_of_triples[0][1].getUri()\n",
    "        e_in_to_e = one_triple_left_map[e_in]   #Find the relevant property from the map\n",
    "        \n",
    "        #Given this information, lets create mappings of template three \n",
    "        for triple in list_of_triples:\n",
    "            \n",
    "            #Making the variables explicit (for the sake of readability)\n",
    "            e_in_in = triple[0].getUri()\n",
    "            e_in_in_to_e_in = triple[2]['object'].getUri()\n",
    "            \n",
    "            #Create a mapping (in keeping with the templates' placeholder names)\n",
    "            mapping = { 'e_in_in':e_in_in, 'e_in_in_to_e_in': e_in_in_to_e_in, 'e_in_to_e':e_in_to_e, 'e_in': e_in }\n",
    "        \n",
    "            #Throw it to a function who will put it in the list with appropriate bookkeeping\n",
    "            fill_specific_template( _template_id=3, _mapping=mapping)\n",
    "            \n",
    "    ''' \n",
    "        Template #4: \n",
    "            SELECT DISTINCT ?uri WHERE { <%(e_out_in)s> <%(e_out_in_to_e_out)s> ?x . ?uri <%(e_to_e_out)s> ?x }\n",
    "        Find e_in and e_in_to_e.\n",
    "    '''       \n",
    "    \n",
    "    #Query the graph for outnodes from e and relevant properties\n",
    "    op = access.return_outnodes('e')\n",
    "    \n",
    "    #Create a list of all these (e_to_e_out, e_out)\n",
    "    one_triple_right_map = { triple[1].getUri(): triple[2]['object'].getUri() for triple in op[0] }\n",
    "    pprint(one_triple_right_map)\n",
    "    \n",
    "    #Collect all e_out_in and e_out_in_to_e_out \n",
    "    op = access.return_innodes('e_out')\n",
    "    \n",
    "    #This 'op' has the e_out_in and the prop for all e_out's. We now need to map one to the other.\n",
    "    for list_of_triples in op:\n",
    "\n",
    "        #Some triple are simply empty. Ignore them.\n",
    "        if len(list_of_triples) == 0:\n",
    "            continue\n",
    "\n",
    "        ### Mapping e_out_in's to relevant e_out's ###\n",
    "    \n",
    "        #Pick one triple from the list.\n",
    "        e_out = list_of_triples[0][1].getUri()\n",
    "        e_to_e_out = one_triple_right_map[e_out]   #Find the relevant property from the map\n",
    "        \n",
    "         #Given this information, lets create mappings of template four \n",
    "        for triple in list_of_triples:\n",
    "            \n",
    "            #Making the variables explicit (for the sake of readability)\n",
    "            e_out_in = triple[0].getUri()\n",
    "            e_out_in_to_e_out = triple[2]['object'].getUri()\n",
    "            \n",
    "            #Create a mapping (in keeping with the templates' placeholder names)\n",
    "            mapping = { 'e_out_in':e_out_in, 'e_out_in_to_e_out': e_out_in_to_e_out, 'e_to_e_out':e_to_e_out, 'e_out': e_out }\n",
    "        \n",
    "            #Throw it to a function who will put it in the list with appropriate bookkeeping\n",
    "            fill_specific_template( _template_id=4, _mapping=mapping, _debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fill_specific_template() takes at least 4 arguments (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d8fcbb186b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#Generate SPARQLS based on subgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfill_templates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#Write the SPARQLs to disk in Pretty Print format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-805e2bc4f501>\u001b[0m in \u001b[0;36mfill_templates\u001b[0;34m(_graph, _uri)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#Throw it to a function who will put it in the list with appropriate bookkeeping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mfill_specific_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_template_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_mapping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fill_specific_template() takes at least 4 arguments (2 given)"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Testing the ability to create subgraph given a URI\n",
    "    Testing the ability to generate sparql templates\n",
    "'''\n",
    "sparqls = {}\n",
    "dbp =  db_interface.DBPedia(_verbose = True)\n",
    "uri = 'http://dbpedia.org/resource/Bareilly'\n",
    "\n",
    "#Generate the local subgraph\n",
    "graph = get_local_subgraph(uri)\n",
    "\n",
    "#Generate SPARQLS based on subgraph\n",
    "fill_templates(graph,_uri=uri)\n",
    "\n",
    "#Write the SPARQLs to disk in Pretty Print format\n",
    "for i in range(1,5):\n",
    "    with open('output/template%d.txt' % i, 'wt') as out:\n",
    "        pprint(sparqls[i], stream=out)\n",
    "for i in range(1,5):\n",
    "    f = open('output/template%s.json' % i, 'wt')\n",
    "    json.dump(sparqls[i],f)\n",
    "    f.close()\n",
    "print \"DONE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
